{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, ServiceContext\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.llms.llm import LLM\n",
    "\n",
    "# imports\n",
    "from llama_index.embeddings.gemini import GeminiEmbedding\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.llms.litellm import LiteLLM\n",
    "import os\n",
    "\n",
    "from llama_index.core.embeddings import BaseEmbedding\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader, StorageContext\n",
    "from llama_index.core import VectorStoreIndex, SimpleKeywordTableIndex\n",
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.core import ComposableGraph\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.response.notebook_utils import display_response\n",
    "from llama_index.core import Settings\n",
    "from dotenv import load_dotenv\n",
    "from base.rag import BaseRag\n",
    "from base.logger import Logger\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.graph_stores.nebula import NebulaGraphStore\n",
    "\n",
    "from pathlib import Path\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.storage.docstore.redis import RedisDocumentStore\n",
    "from llama_index.storage.index_store.redis import RedisIndexStore\n",
    "\n",
    "load_dotenv(\"/home/t/atest/.global_env\")\n",
    "\n",
    "logger = Logger().get_logger()\n",
    "REDIS_HOST = os.getenv(\"REDIS_HOST\", \"127.0.0.1\")\n",
    "REDIS_PORT = os.getenv(\"REDIS_PORT\", 6379)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = ['gemini/gemini-2.0-flash']\n",
    "\n",
    "llm = LiteLLM(temperature=0, model=models[0])\n",
    "embed_model = GeminiEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.embed_model = embed_model\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"NEBULA_USER\"] = \"root\"\n",
    "os.environ[\"NEBULA_PASSWORD\"] = \"nebula\"  # default is \"nebula\"\n",
    "os.environ[\n",
    "    \"NEBULA_ADDRESS\"\n",
    "] = \"127.0.0.1:9669\"  # assumed we have NebulaGraph installed locally\n",
    "\n",
    "space_name = \"llamaindex\"\n",
    "edge_types, rel_prop_names = [\"relationship\"], [\n",
    "    \"relationship\"\n",
    "]  # default, could be omit if create from an empty kg\n",
    "tags = [\"entity\"]  # default, could be omit if create from an empty kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# graph_store = NebulaGraphStore(\n",
    "#     space_name=space_name,\n",
    "#     edge_types=edge_types,\n",
    "#     rel_prop_names=rel_prop_names,\n",
    "#     tags=tags,\n",
    "# )\n",
    "# storage_context = StorageContext.from_defaults(graph_store=graph_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "DEFAULT_CHUNK_SIZE=2048\n",
    "DEFAULT_CHUNK_OVERLAP = 200\n",
    "\n",
    "class SiteRag(BaseRag):\n",
    "\n",
    "    def __init__(self, llm:LLM, storage:StorageContext, embed_model:BaseEmbedding=None,\n",
    "                 chunk_size:int=DEFAULT_CHUNK_SIZE, chunk_overlap:int=DEFAULT_CHUNK_OVERLAP):\n",
    "        self.reader = None\n",
    "\n",
    "        self.llm = llm\n",
    "        \n",
    "        if embed_model:\n",
    "            self.embed_model = embed_model\n",
    "            Settings.embed_model = self.embed_model\n",
    "\n",
    "        Settings.llm = self.llm\n",
    "        Settings.chunk_size = chunk_size\n",
    "        Settings.chunk_overlap = chunk_overlap\n",
    "        \n",
    "        self.storage_context=storage\n",
    "\n",
    "    \n",
    "    def _ingest(self, dir:Path)->None:\n",
    "        self.reader =SimpleDirectoryReader(input_dir=dir)\n",
    "        documents = self.reader.load_data()\n",
    "        nodes = SentenceSplitter().get_nodes_from_documents(documents)\n",
    "\n",
    "\n",
    "        self.storage_context.docstore.add_documents(nodes)\n",
    "        logger.info(f\"{len(self.storage_context.docstore.docs)} Ingested.\")\n",
    "        \n",
    "    \n",
    "    \n",
    "    # def _query(self, query:str, n:int)->str:\n",
    "    #     self.query_engine = self.storage_context.as_query_engine()\n",
    "    #     list_response = self.query_engine.query(\"What is a summary of this document?\")\n",
    "        \n",
    "    #     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core.agent.workflow import FunctionAgent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.readers.wikipedia import WikipediaReader\n",
    "import asyncio\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = WikipediaReader().load_data(pages=['avengers (2012)', 'Ironman (2008)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = [\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    transformations = []\n",
    "    \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a RAG tool using LlamaIndex\n",
    "# documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = query_engine.query(\"what does  Asgardian Loki  do\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn = out.source_nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(sn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.remote import RemoteReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = RemoteReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p  = r.load_data(url = 'https://en.wikipedia.org/wiki/Nick_Fury_(Marvel_Cinematic_Universe)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html2text\n",
    "# h = html2text.HTML2Text()\n",
    "# h.ignore_links=True\n",
    "# h.ignore_tables=True\n",
    "# h.ignore_mailto_links=True\n",
    "# h.ignore_emphasis=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_docs(url):\n",
    "    r = RemoteReader()\n",
    "    h = html2text.HTML2Text()\n",
    "    \n",
    "    h.ignore_links=True\n",
    "    h.ignore_tables=True\n",
    "    h.ignore_mailto_links=True\n",
    "    h.ignore_emphasis=True\n",
    "    \n",
    "    docs  = r.load_data(url = url)\n",
    "    clean_doc = []\n",
    "    for i in docs:\n",
    "        try:\n",
    "            clean_doc.append(h.handle(i.text))\n",
    "        except Exception :\n",
    "            logger.error(f'Failed to get web content for {url}')\n",
    "            clean_doc.append(None)\n",
    "        \n",
    "    for i,j in zip(docs, clean_doc):\n",
    "        i.set_content(j) \n",
    "    \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = get_url_docs('https://en.wikipedia.org/wiki/Nick_Fury_(Marvel_Cinematic_Universe)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_dotenv('../../.global_env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import cache\n",
    "from nest_asyncio import apply\n",
    "apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "from llama_index.core.base.base_query_engine import BaseQueryEngine\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "# A dictionary-based manual cache (because lists are unhashable for lru_cache)\n",
    "_query_engine_cache = {}\n",
    "\n",
    "def _hash_urls(urls: list[str]) -> int:\n",
    "    \"\"\"Create a hashable key from the list of URLs.\"\"\"\n",
    "    return hash(frozenset(urls))  # Using frozenset so order doesn't matter\n",
    "\n",
    "def get_query_engine(urls: list[str]) -> BaseQueryEngine:\n",
    "    \"\"\"Return a cached query engine if available, otherwise create a new one.\"\"\"\n",
    "    cache_key = _hash_urls(urls)\n",
    "    \n",
    "    if cache_key in _query_engine_cache:\n",
    "        return _query_engine_cache[cache_key]\n",
    "    \n",
    "    documents = list(chain.from_iterable(get_url_docs(url) for url in urls))\n",
    "\n",
    "    index = VectorStoreIndex(use_async=True, nodes=documents, transformations=[])\n",
    "    # retriever=index.as_retriever()\n",
    "    query_engine = index.as_query_engine()\n",
    "    \n",
    "    _query_engine_cache[cache_key] = query_engine  # Cache the result\n",
    "    \n",
    "    return query_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import NodeWithScore\n",
    "\n",
    "\n",
    "\n",
    "def get_answers(urls:list[str], query:str)->NodeWithScore:\n",
    "    query_engine = get_query_engine(urls)\n",
    "    out = query_engine.query(query)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['https://en.wikipedia.org/wiki/Nick_Fury_(Marvel_Cinematic_Universe)', 'https://en.wikipedia.org/wiki/Maria_Hill', 'https://en.wikipedia.org/wiki/Avengers:_Age_of_Ultron']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = list(chain.from_iterable(get_url_docs(url) for url in urls))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spli = SentenceSplitter(secondary_chunking_regex=r1)\n",
    "\n",
    "ss = spli.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = [SentenceSplitter(secondary_chunking_regex=r1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = VectorStoreIndex(nodes=documents[:1], transformations=transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = get_answers(urls = urls,\n",
    "                  query = \"what is maria hill 's full name\",\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q= get_query_engine(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = q.query('who plays maria hill in live actionmoview')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
